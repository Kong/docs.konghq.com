## Changelog

### {{site.base_gateway}} 3.10.0.0

* Introduced the new **AI RAG Injector** plugin which allows you to inject data from external sources into the LLM prompt. This plugin is designed to work with the AI Proxy plugin and can be used to enhance the context of the LLM's request by providing additional information from various sources.